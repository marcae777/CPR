{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/wmf/wmf.py:18: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-1a4f60ae0696>\", line 1, in <module>\n",
      "    from cpr.Nivel import Nivel\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/cpr/Nivel.py\", line 15, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 72, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "from cpr.Nivel import Nivel\n",
    "from cpr.SqlDb import SqlDb\n",
    "import cpr.information as info\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def duplicate_existing_table(self,table_name):\n",
    "    '''\n",
    "    inserts data into SQL table from list of fields and values\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name   = SQL db table name\n",
    "    Returns\n",
    "    -------\n",
    "    Sql sentence,str\n",
    "    '''\n",
    "    df = self.read_sql('describe %s'%table_name)\n",
    "    df['Null'][df['Null']=='NO'] = 'NOT NULL'\n",
    "    df['Null'][df['Null']=='YES'] = 'NULL'\n",
    "    sentence = 'CREATE TABLE %s ('%table_name\n",
    "    if df[df['Extra']=='auto_increment'].empty:\n",
    "        pk = None\n",
    "    else:\n",
    "        pk = df[df['Extra']=='auto_increment']['Field'].values[0]\n",
    "    for id,serie in df.iterrows():\n",
    "        if (serie.Default=='0') or (serie.Default is None):\n",
    "            row = '%s %s %s'%(serie.Field,serie.Type,serie.Null)\n",
    "        else:\n",
    "            if (serie.Default == 'CURRENT_TIMESTAMP'):\n",
    "                serie.Default = \"DEFAULT %s\"%serie.Default\n",
    "            elif serie.Default == '0000-00-00':\n",
    "                serie.Default = \"DEFAULT '1000-01-01 00:00:00'\"\n",
    "            else:\n",
    "                serie.Default = \"DEFAULT '%s'\"%serie.Default\n",
    "            row = '%s %s %s %s'%(serie.Field,serie.Type,serie.Null,serie.Default)\n",
    "        if serie.Extra:\n",
    "            row += ' %s,'%serie.Extra\n",
    "        else:\n",
    "            row += ',' \n",
    "        sentence+=row\n",
    "    if pk:\n",
    "        sentence +='PRIMARY KEY (%s)'%pk\n",
    "    else:\n",
    "        sentence = sentence[:-1]\n",
    "    sentence +=');'\n",
    "    return sentence\n",
    "\n",
    "def siata_remote_data_to_transfer(start,end):\n",
    "    '''\n",
    "    inserts data into SQL table from list of fields and values\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name   = SQL db table name\n",
    "    Returns\n",
    "    -------\n",
    "    Sql sentence,str\n",
    "    '''\n",
    "    remote = cpr.Nivel(**cpr.info.REMOTE)\n",
    "    codigos_str = '('+str(list(self.infost.index)).strip('[]')+')'\n",
    "    df = remote.read_sql('SELECT * FROM datos WHERE cliente in %s and %s'%(codigos_str,self.fecha_hora_query(start,end)))\n",
    "    return df\n",
    "\n",
    "def default_values(self,table_name):\n",
    "    '''\n",
    "    inserts data into SQL table from list of fields and values\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name   = SQL db table name\n",
    "    Returns\n",
    "    -------\n",
    "    Sql sentence,str\n",
    "    '''\n",
    "    describe_table = self.read_sql('describe %s'%table_name)\n",
    "    not_null = describe_table['Default'].notnull()\n",
    "    default_values = describe_table[['Field','Default','Type']][not_null].set_index('Field')[['Default','Type']]\n",
    "    return default_values\n",
    "\n",
    "def filter_data_to_update(table_name,path):\n",
    "    '''\n",
    "    inserts data into SQL table from list of fields and values\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name   = SQL db table name\n",
    "    Returns\n",
    "    -------\n",
    "    Sql sentence,str\n",
    "    '''\n",
    "    default = default_values(self,table_name)\n",
    "    if default[default['Type']=='time'].empty:\n",
    "        time_fields = None\n",
    "    else:\n",
    "        time_fields = default[default['Type']=='time']\n",
    "    for index,s in time_fields.iterrows():\n",
    "        df = pd.read_csv(path,index_col=0)\n",
    "        df[index] = df[index].apply(lambda x:str(x)[6:15])\n",
    "    return df.applymap(lambda x:str(x))\n",
    "\n",
    "def insert_in_datos(path):\n",
    "    '''\n",
    "    inserts data into SQL table from list of fields and values\n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name   = SQL db table name\n",
    "    Returns\n",
    "    -------\n",
    "    Sql sentence,str\n",
    "    '''\n",
    "    inicia = datetime.datetime.now()\n",
    "    table_name = 'datos'\n",
    "    df = filter_data_to_update(table_name,path)\n",
    "    query = 'INSERT INTO %s '%table_name+'('+str(list(df.columns)).strip('[]').replace(\"'\",'')+') VALUES '\n",
    "    for id,s in df.iterrows():\n",
    "        query+=('('+str(list(s.values)).strip('[]'))+'), '\n",
    "    query = query[:-2]+' ON DUPLICATE KEY UPDATE '\n",
    "    describe = self.read_sql('describe %s;'%table_name)\n",
    "    not_primary_keys = describe[describe['Key']!='PRI']\n",
    "    if not_primary_keys.empty:\n",
    "        not_primary_keys = describe.Field.values\n",
    "    else:\n",
    "        not_primary_keys = not_primary_keys.Field.values\n",
    "    for key in not_primary_keys:\n",
    "        query+=('%s = VALUES(%s), '%(key,key))\n",
    "    query=query[:-2]\n",
    "    finaliza = datetime.datetime.now()\n",
    "    self.user = 'root'\n",
    "    self.passwd = 'mcanoYw2E#'\n",
    "    self.execute_sql('SET GLOBAL max_allowed_packet=1073741824;')\n",
    "    self.execute_sql(query)\n",
    "    print(finaliza - inicia)\n",
    "    \n",
    "#os.system(\"scp -r mcano@siata.gov.co:data_migration/* ../../cprweb/src/media/data_migration/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recordar modificar info.DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mcano/Dev/cprweb/src/media/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = SqlDb(**info.REMOTE)\n",
    "folder_path = info.DATA_PATH+'weekly_data'\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "for path in files:\n",
    "    insert_in_datos(folder_path+path)\n",
    "    print(path)\n",
    "level = cpr.Nivel(codigo=99,**cpr.info.LOCAL).level('2018-03-01',datetime.datetime.now())\n",
    "\n",
    "april = [] # para agregar abril a nivel futuro\n",
    "for path in files:\n",
    "    if path[:20] == 'weekly_level_2018-04':\n",
    "        april.append(path)\n",
    "\n",
    "date_offset = pd.to_datetime(level.dropna().index[-1])\n",
    "date = date_offset-pd.to_datetime(pd.read_csv(folder_path + april[0],index_col=0)['fecha'][0])\n",
    "for path in april:\n",
    "    raw_data = pd.read_csv(folder_path + path,index_col=0)\n",
    "    raw_data['fecha'] = (pd.to_datetime(raw_data['fecha']) + datetime.timedelta(days=date.days)).apply(lambda x:x.strftime('%Y-%m-%d'))\n",
    "    raw_data.to_csv(folder_path+'future_'+path)\n",
    "    insert_in_datos(folder_path+'future_'+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aforos migration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTER TABLE myusers_hydrodata ADD UNIQUE (fk_id,fecha);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Nivel(codigo=99,**info.LOCAL)\n",
    "aforo_nueva = pd.read_csv('/home/mcano/Dev/cprweb/src/media/data_migration/aforo_nueva.csv').set_index('id_aforo')[['fecha','id_estacion_asociada']]\n",
    "levantamiento_aforo_nueva = pd.read_csv('/home/mcano/Dev/cprweb/src/media/data_migration/levantamiento_aforo_nueva.csv')\n",
    "levantamiento_aforo_nueva = levantamiento_aforo_nueva[['id_aforo','vertical','x','y']].set_index('id_aforo')\n",
    "df = aforo_nueva.join(levantamiento_aforo_nueva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(set(df.index))\n",
    "aforo_nueva = aforo_nueva.loc[ids]\n",
    "\n",
    "indexes = self.read_sql('select id,codigo from estaciones_estaciones').set_index('codigo')['id']\n",
    "indexes.index = np.array(indexes.index,int)\n",
    "date_format = '%Y-%m-%d %H:%M'\n",
    "table = 'myusers_item'\n",
    "now = datetime.datetime.now().strftime(date_format)\n",
    "\n",
    "revisar = []\n",
    "query = 'INSERT INTO %s (fecha,hora,minuto,timestamp,updated,offset,item_fk_id,user_id,tipo_salida,x_lamina) VALUES '%(table)\n",
    "\n",
    "for id_aforo,s in aforo_nueva.iterrows():\n",
    "    count = 0\n",
    "    try:\n",
    "        codigo = s.id_estacion_asociada\n",
    "        fecha = pd.to_datetime(s.fecha)\n",
    "        hora = int(fecha.strftime('%H'))\n",
    "        item_fk_id = indexes[codigo]\n",
    "        offset = self.infost.loc[codigo,'offset']\n",
    "        x_lamina = self.infost.loc[codigo,'x_sensor']\n",
    "        try:\n",
    "            id = self.read_sql(\"select id from myusers_item where item_fk_id = '%s' and fecha = '%s' and hora = '%s'\"%(item_fk_id,fecha.strftime('%Y-%m-%d'),hora)).iloc[0]['id']\n",
    "        except:\n",
    "            id = None\n",
    "        if id:\n",
    "            pass\n",
    "        else:\n",
    "            format = (fecha.strftime('%Y-%m-%d'),\n",
    "                      str(hora),\n",
    "                      str(int(fecha.strftime('%M'))),\n",
    "                      now,\n",
    "                      now,\n",
    "                      offset,\n",
    "                      str(item_fk_id),\n",
    "                      str(1),\n",
    "                      'siata-batimetria',\n",
    "                     str(x_lamina))\n",
    "            query += str(format)+','\n",
    "            count += 1\n",
    "    except:\n",
    "        revisar.append(id_aforo)\n",
    "query = query[:-1]\n",
    "if count == 0:\n",
    "    query = None\n",
    "if query:\n",
    "    self.execute_sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Nivel(codigo=99,**info.LOCAL)\n",
    "table = 'myusers_topo'\n",
    "query = 'INSERT INTO %s (user_id,fk_id,vertical,x,y,timestamp,updated) VALUES '%(table)\n",
    "date_format = '%Y-%m-%d %H:%M'\n",
    "now = datetime.datetime.now().strftime(date_format)\n",
    "indexes = self.read_sql('select id,codigo from estaciones_estaciones').set_index('codigo')['id']\n",
    "indexes.index = np.array(indexes.index,int)\n",
    "\n",
    "for id_aforo,s in aforo_nueva.iterrows():\n",
    "    try:\n",
    "        count = 0\n",
    "        codigo = s.id_estacion_asociada\n",
    "        fecha = pd.to_datetime(s.fecha)\n",
    "        hora = int(fecha.strftime('%H'))\n",
    "        item_fk_id = indexes[codigo]\n",
    "        x_lamina = float(self.infost.loc[codigo,'x_sensor'])\n",
    "        id = self.read_sql(\"select id from myusers_item where item_fk_id = '%s' and fecha = '%s' and hora = '%s'\"%(item_fk_id,fecha.strftime('%Y-%m-%d'),hora)).iloc[0]['id']\n",
    "        lev = levantamiento_aforo_nueva.loc[id_aforo]\n",
    "        lev = self.adjust_topo(lev,x_lamina).reset_index()\n",
    "        lev.columns = ['vertical','x','y']\n",
    "        for loc in range(lev.index.size):\n",
    "            query +=  str((str(1),\n",
    "                       str(int(id)),\n",
    "                       str(int(lev.iloc[loc].vertical)),\n",
    "                       str(lev.iloc[loc].x),\n",
    "                       str(lev.iloc[loc].y),\n",
    "                       now,\n",
    "                       now))+','\n",
    "    except:\n",
    "        pass\n",
    "query = query[:-1]\n",
    "self.execute_sql(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
